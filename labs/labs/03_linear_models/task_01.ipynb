{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes(as_frame=True, scaled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(\n",
    "    data.frame,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().round(2).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    train_dataset.corr(),\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    ")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.drop(columns='target')\n",
    "y_train = train_dataset['target'].values\n",
    "\n",
    "X_test = test_dataset.drop(columns='target')\n",
    "y_test = test_dataset['target'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um modelo linear simples e alguns mais \"chiques\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma mega-função para rodar o experimento completo para cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    model,\n",
    "    get_model_params_fn,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "):\n",
    "\n",
    "    def compute_predictions(fitted_model, X_train, X_test):\n",
    "        y_train_pred = fitted_model.predict(X_train)\n",
    "        y_test_pred = fitted_model.predict(X_test)\n",
    "\n",
    "        return y_train_pred, y_test_pred\n",
    "\n",
    "    def compute_rmse(fitted_model, y, y_pred):\n",
    "        return root_mean_squared_error(y, y_pred)\n",
    "\n",
    "    def print_rmse(label, rmse):\n",
    "        print(f'{label} RMSE: {rmse:.2f}')\n",
    "\n",
    "    def print_linear_model_formula(intercept, coefs):\n",
    "        print('y_pred = ')\n",
    "        print(f'      ({intercept: 8.2f})')\n",
    "        for i, coef in enumerate(coefs):\n",
    "            print(f'    + ({coef: 8.2f}) * X_{i+1}')\n",
    "        print()\n",
    "\n",
    "        fitted_model = model.fit(X_train, y_train)\n",
    "        y_train_pred, y_test_pred = compute_predictions(\n",
    "            fitted_model,\n",
    "            X_train,\n",
    "            X_test,\n",
    "        )\n",
    "\n",
    "    def plot_residuals(y_train, y_train_pred, y_test, y_test_pred):\n",
    "\n",
    "        def plot_scatter_and_residuals(\n",
    "            y,\n",
    "            y_pred,\n",
    "            color,\n",
    "            label,\n",
    "        ):\n",
    "            plt.scatter(\n",
    "                y,\n",
    "                y_pred,\n",
    "                color=color,\n",
    "                marker='o',\n",
    "                label=label,\n",
    "                alpha=0.5,\n",
    "            )\n",
    "            for y_value, y_pred_value in zip(y, y_pred):\n",
    "                plt.plot(\n",
    "                    [y_value, y_value],\n",
    "                    [y_value, y_pred_value],\n",
    "                    color=color,\n",
    "                    linestyle='--',\n",
    "                    lw=0.5,\n",
    "                    alpha=0.5,\n",
    "                )\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plot_scatter_and_residuals(y_train, y_train_pred, 'blue', 'Train')\n",
    "        plot_scatter_and_residuals(y_test, y_test_pred, 'orange', 'Test')\n",
    "\n",
    "        min_y = min(y_train.min(), y_test.min())\n",
    "        max_y = max(y_train.max(), y_test.max())\n",
    "        plt.plot(\n",
    "            [min_y, max_y],\n",
    "            [min_y, max_y],\n",
    "            'k--',\n",
    "            lw=2,\n",
    "            label='Perfect prediction',\n",
    "        )\n",
    "        plt.xlim(min_y, max_y)\n",
    "        plt.ylim(min_y, max_y)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.grid()\n",
    "        plt.xlabel('True values')\n",
    "        plt.ylabel('Predicted values')\n",
    "        plt.title('True vs Predicted values')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    fitted_model = model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred, y_test_pred = compute_predictions(\n",
    "        fitted_model,\n",
    "        X_train,\n",
    "        X_test,\n",
    "    )\n",
    "\n",
    "    train_rmse = compute_rmse(fitted_model, y_train, y_train_pred)\n",
    "    test_rmse = compute_rmse(fitted_model, y_test, y_test_pred)\n",
    "\n",
    "    print_rmse('Train', train_rmse)\n",
    "    print_rmse('Test', test_rmse)\n",
    "\n",
    "    intercept, coefs = get_model_params_fn(fitted_model)\n",
    "    print_linear_model_formula(intercept, coefs)\n",
    "\n",
    "    plot_residuals(\n",
    "        y_train,\n",
    "        y_train_pred,\n",
    "        y_test,\n",
    "        y_test_pred,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo os modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O modelo mais simples possível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def create_simple_linear_model():\n",
    "    return LinearRegression()\n",
    "\n",
    "\n",
    "def get_simple_model_params(model):\n",
    "    return model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um modelo simples mas precedido de uma pipeline de pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O código da pipeline de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "\n",
    "def create_pipeline_model_with_preprocessing(model):\n",
    "\n",
    "    def create_basic_preprocessing_pipeline():\n",
    "        # Create the various stages of the Pipeline. You could do it directly \n",
    "        # in the Pipeline constructor, but this is more readable, though a bit\n",
    "        # more verbose.\n",
    "\n",
    "        # The imputer will replace missing values with the mean of the column.\n",
    "        imputer_stage = SimpleImputer(strategy='mean')\n",
    "\n",
    "        # The polynomial features stage will create polynomial features of \n",
    "        # degree 2.\n",
    "        poly_stage = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "        # The scaler will standardize the features (mean=0, variance=1).\n",
    "        scaler_stage = StandardScaler()\n",
    "\n",
    "        # Now join them together in a Pipeline.\n",
    "        preprocessing_pipe = Pipeline([\n",
    "            ('imputer', imputer_stage),\n",
    "            ('poly', poly_stage),\n",
    "            ('scaler', scaler_stage),\n",
    "        ])\n",
    "\n",
    "        return preprocessing_pipe\n",
    "\n",
    "    # Create the preprocessing pipeline.\n",
    "    preprocessing_pipe = create_basic_preprocessing_pipeline()\n",
    "\n",
    "    # Join the preprocessing and model stages in a single pipeline.\n",
    "    # This is the final pipeline that will be used for training and prediction.\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessing', preprocessing_pipe),\n",
    "        ('model', model),\n",
    "    ])\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def get_pipeline_model_params(model):\n",
    "    # Get the model stage from the pipeline.\n",
    "    model_stage = model.named_steps['model']\n",
    "\n",
    "    # Get the intercept and coefficients from the model.\n",
    "    intercept = model_stage.intercept_\n",
    "    coefs = model_stage.coef_\n",
    "\n",
    "    return intercept, coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O modelo simples com pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_model_with_preprocessing():\n",
    "    # Create the regression model.\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Create the pipeline model.\n",
    "    pipe = create_pipeline_model_with_preprocessing(model)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um modelo de regressão Ridge com pre-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def create_ridge_model_with_preprocessing():\n",
    "    # Create the regression model with Ridge regularization.\n",
    "    model = Ridge(alpha=5.0)\n",
    "\n",
    "    # Create the pipeline model.\n",
    "    pipe = create_pipeline_model_with_preprocessing(model)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um modelo de regressão Lasso com pre-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def create_lasso_model_with_preprocessing():\n",
    "    # Create the regression model with Ridge regularization.\n",
    "    model = Lasso(alpha=5.0)\n",
    "\n",
    "    # Create the pipeline model.\n",
    "    pipe = create_pipeline_model_with_preprocessing(model)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_linear_model = create_simple_linear_model()\n",
    "simple_linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = create_linear_model_with_preprocessing()\n",
    "linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = create_ridge_model_with_preprocessing()\n",
    "ridge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = create_lasso_model_with_preprocessing()\n",
    "lasso_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão simples: train-test-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_val,\n",
    "    X_test_val,\n",
    "    y_train_val,\n",
    "    y_test_val,\n",
    ") = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    simple_linear_model,\n",
    "    get_simple_model_params,\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    X_test_val,\n",
    "    y_test_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    linear_model,\n",
    "    get_pipeline_model_params,\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    X_test_val,\n",
    "    y_test_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    ridge_model,\n",
    "    get_pipeline_model_params,\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    X_test_val,\n",
    "    y_test_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    lasso_model,\n",
    "    get_pipeline_model_params,\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    X_test_val,\n",
    "    y_test_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão mais \"sofisticada\": validação cruzada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = 5\n",
    "\n",
    "simple_model_cv = cross_val_score(\n",
    "    simple_linear_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "linear_model_cv = cross_val_score(\n",
    "    linear_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "ridge_model_cv = cross_val_score(\n",
    "    ridge_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "lasso_model_cv = cross_val_score(\n",
    "    lasso_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_results(model_name, cv_results):\n",
    "    # Convert negative RMSE to positive RMSE.\n",
    "    cv_results = -cv_results\n",
    "\n",
    "    # Print the cross-validation results.\n",
    "    print(f'{model_name} CV results:')\n",
    "    print(cv_results)\n",
    "\n",
    "    # Compute mean and standard deviation of RMSE.\n",
    "    mean_rmse = cv_results.mean()\n",
    "    std_rmse = cv_results.std()\n",
    "\n",
    "    # Print the results.\n",
    "    print(f'RMSE: {mean_rmse:.2f} +/- {std_rmse:.2f}')\n",
    "    print()\n",
    "\n",
    "print_cv_results('Simple Linear Model', simple_model_cv)\n",
    "print_cv_results('Linear Model', linear_model_cv)\n",
    "print_cv_results('Ridge Model', ridge_model_cv)\n",
    "print_cv_results('Lasso Model', lasso_model_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de hiperparâmetros com validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modelo simples não tem nada para escolher, o desempenho é aquele mesmo.\n",
    "\n",
    "- Os demais modelos tem escolhas a serem feitas no estágio de pré-processamento.\n",
    "\n",
    "- Os modelos \"ridge\" e \"lasso\" tem a escolha do hiperparâmetro `alpha`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desempenho do modelo linear simples é obtido simplesmente com `cross_val_score`, como feito acima, não precisa repetir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_results('Simple Linear Model', simple_model_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "param_grid_preprocessing = {\n",
    "    'preprocessing__poly__degree': [1, 2],\n",
    "    'preprocessing__scaler__with_mean': [True, False],\n",
    "    'preprocessing__scaler__with_std': [True, False],\n",
    "}\n",
    "\n",
    "param_grid_model = {\n",
    "    'model__alpha': np.logspace(-1, 5, 6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcula o desempenho do modelo linear com pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_linear_model = GridSearchCV(\n",
    "    linear_model,\n",
    "    param_grid_preprocessing,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters for linear model:')\n",
    "print(grid_linear_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_linear_model = grid_linear_model.best_estimator_\n",
    "best_linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score for ridge model:')\n",
    "print(grid_linear_model.best_score_.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_linear_model.cv_results_) \\\n",
    "    .sort_values(by='rank_test_score') \\\n",
    "    .iloc[:10, :] \\\n",
    "    .loc[:, ['params', 'mean_test_score', 'std_test_score']] \\\n",
    "    .round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcula o desempenho do modelo Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note o truque de Python para concatenar dicionários.\n",
    "# O operador ** é usado para expandir o dicionário.\n",
    "# Isso é útil para combinar os parâmetros de pré-processamento e do modelo.\n",
    "param_grid_ridge = {\n",
    "    **param_grid_preprocessing,\n",
    "    **param_grid_model,\n",
    "}\n",
    "\n",
    "grid_ridge_model = GridSearchCV(\n",
    "    ridge_model,\n",
    "    param_grid_ridge,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters for ridge model:')\n",
    "print(grid_ridge_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score for ridge model:')\n",
    "print(grid_ridge_model.best_score_.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_ridge_model.cv_results_) \\\n",
    "    .sort_values(by='rank_test_score') \\\n",
    "    .iloc[:10, :] \\\n",
    "    .loc[:, ['params', 'mean_test_score', 'std_test_score']] \\\n",
    "    .round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcula o desempenho do modelo Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note o truque de Python para concatenar dicionários.\n",
    "# O operador ** é usado para expandir o dicionário.\n",
    "# Isso é útil para combinar os parâmetros de pré-processamento e do modelo.\n",
    "param_grid_lasso = {\n",
    "    **param_grid_preprocessing,\n",
    "    **param_grid_model,\n",
    "}\n",
    "\n",
    "grid_lasso_model = GridSearchCV(\n",
    "    lasso_model,\n",
    "    param_grid_lasso,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_lasso_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters for lasso model:')\n",
    "print(grid_lasso_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score for lasso model:')\n",
    "print(grid_lasso_model.best_score_.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_lasso_model.cv_results_) \\\n",
    "    .sort_values(by='rank_test_score') \\\n",
    "    .iloc[:10, :] \\\n",
    "    .loc[:, ['params', 'mean_test_score', 'std_test_score']] \\\n",
    "    .round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sumário dos melhores escores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Simple linear model: {simple_model_cv.mean().round(2)}')\n",
    "print(f'Linear model: {grid_linear_model.best_score_.round(2)}')\n",
    "print(f'Ridge: {grid_ridge_model.best_score_.round(2)}')\n",
    "print(f'Lasso: {grid_lasso_model.best_score_.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atividades\n",
    "\n",
    "- Verifique os coeficientes do melhor modelo LASSO para ver quais *features* são mais relevantes.\n",
    "\n",
    "- Treine um modelo linear sem regularização com apenas as features escolhidas pelo LASSO, compare com o modelo linear completo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
